{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966b8e4b-0a48-417f-ac83-216122d2e4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "from tqdm.notebook import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset,DataLoader, TensorDataset\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import optuna\n",
    "from sklearn.metrics import f1_score,accuracy_score, recall_score, confusion_matrix,precision_score\n",
    "from torch.utils.data import random_split\n",
    "import re\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0282be-68f5-4975-b8cf-b08b038d2bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "g = torch.Generator()\n",
    "g.manual_seed(42)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b984d4c-e643-4768-b3a9-67a38c1b93b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionBlock(nn.Module):\n",
    "    def __init__(self, F_g, F_l, F_int):\n",
    "        super(AttentionBlock, self).__init__()\n",
    "        self.W_g = nn.Sequential(\n",
    "            nn.Conv2d(F_g, F_int, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(F_int)\n",
    "        )\n",
    "        self.W_x = nn.Sequential(\n",
    "            nn.Conv2d(F_l, F_int, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(F_int)\n",
    "        )\n",
    "        self.psi = nn.Sequential(\n",
    "            nn.Conv2d(F_int, 1, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, g, x):\n",
    "        # g: gating signa\n",
    "        # x: encoder's skip connection\n",
    "        g1 = self.W_g(g)\n",
    "        x1 = self.W_x(x)\n",
    "        psi = self.relu(g1 + x1)\n",
    "        psi = self.psi(psi)\n",
    "        return x * psi  # skip connection transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f56aa8-d23c-4ffe-aebb-7e9078ba8c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNetAutoencoder(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=1, features=[32, 64, 128, 256]):\n",
    "        super(UNetAutoencoder, self).__init__()\n",
    "        self.encoder_layers = nn.ModuleList()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Encoder: ReLU \n",
    "        for feature in features:\n",
    "            self.encoder_layers.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Conv2d(in_channels, feature, kernel_size=3, padding=1),\n",
    "                    nn.BatchNorm2d(feature),\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.Conv2d(feature, feature, kernel_size=3, padding=1),\n",
    "                    nn.BatchNorm2d(feature),\n",
    "                    nn.ReLU(inplace=True)\n",
    "                )\n",
    "            )\n",
    "            in_channels = feature\n",
    "\n",
    "        # Bottleneck: ReLU \n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Conv2d(features[-1], features[-1]*2, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(features[-1]*2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(features[-1]*2, features[-1]*2, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(features[-1]*2),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        # Decoder: ReLU + Attention \n",
    "        self.upconvs = nn.ModuleList()\n",
    "        self.decoder_layers = nn.ModuleList()\n",
    "        self.attention_blocks = nn.ModuleList()\n",
    "\n",
    "        for feature in reversed(features):\n",
    "            up_in_channels = features[-1]*2 if feature == features[-1] else feature*2\n",
    "            self.upconvs.append(\n",
    "                nn.ConvTranspose2d(up_in_channels, feature, kernel_size=2, stride=2)\n",
    "            )\n",
    "            self.attention_blocks.append(\n",
    "                AttentionBlock(F_g=feature, F_l=feature, F_int=feature // 2)\n",
    "            )\n",
    "            self.decoder_layers.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Conv2d(feature * 2, feature, kernel_size=3, padding=1),\n",
    "                    nn.BatchNorm2d(feature),\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.Conv2d(feature, feature, kernel_size=3, padding=1),\n",
    "                    nn.BatchNorm2d(feature),\n",
    "                    nn.ReLU(inplace=True)\n",
    "                )\n",
    "            )\n",
    "\n",
    "        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
    "        self.activation = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        skip_connections = []\n",
    "        for encoder in self.encoder_layers:\n",
    "            x = encoder(x)\n",
    "            skip_connections.append(x)\n",
    "            x = self.pool(x)\n",
    "        \n",
    "        x = self.bottleneck(x)\n",
    "        skip_connections = skip_connections[::-1]\n",
    "\n",
    "        for idx in range(len(self.upconvs)):\n",
    "            x = self.upconvs[idx](x)\n",
    "            skip_connection = skip_connections[idx]\n",
    "            if x.shape != skip_connection.shape:\n",
    "                diffY = skip_connection.shape[2] - x.shape[2]\n",
    "                diffX = skip_connection.shape[3] - x.shape[3]\n",
    "                x = F.pad(x, [diffX // 2, diffX - diffX // 2, diffY // 2, diffY - diffY // 2])\n",
    "\n",
    "            skip_connection = self.attention_blocks[idx](g=x, x=skip_connection)\n",
    "            x = torch.cat((skip_connection, x), dim=1)\n",
    "            x = self.decoder_layers[idx](x)\n",
    "\n",
    "        x = self.final_conv(x)\n",
    "        return self.activation(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a59ccf-e39d-4c0b-a012-24266f0e5a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_single_channel_transform(channel_index, size=(200, 200), train=False):\n",
    "    if train:\n",
    "        return transforms.Compose([\n",
    "            transforms.Lambda(lambda x: x[channel_index, :, :].unsqueeze(0)), \n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize(size),\n",
    "            transforms.ColorJitter(brightness=(0.5, 1.5)),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "    else:\n",
    "        return transforms.Compose([\n",
    "            transforms.Lambda(lambda x: x[channel_index, :, :].unsqueeze(0)),\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize(size),\n",
    "            transforms.ToTensor()\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d47cb7-38ff-4ede-a9a7-3c070cea987c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensorClassificationDataset(Dataset):\n",
    "    def __init__(self, tensor_list, label_list):\n",
    "        self.tensors = tensor_list\n",
    "        self.labels = label_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tensors)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.tensors[idx], self.labels[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1848bb27-3f01-41c0-8e95-39e635ae2a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_tensors, labels, days, sample_ids):\n",
    "\n",
    "        self.data_tensors = data_tensors\n",
    "        self.labels = labels\n",
    "        self.days = days\n",
    "        self.sample_ids = sample_ids\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_tensors)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data_tensors[idx]\n",
    "        y = self.labels[idx]\n",
    "        d = self.days[idx]\n",
    "        s = self.sample_ids[idx]\n",
    "        return x, y, d, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99e7383-0f94-49d6-8805-a4d93825427b",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_index= 1\n",
    "target_width, target_height = 200,200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d38301-d1e2-4a83-b607-1624cd3203f5",
   "metadata": {},
   "source": [
    "### Control Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b295a027-81f0-4a90-861d-83945685f9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = .\n",
    "csv_files = glob.glob(os.path.join(folder_path, '*.csv'))\n",
    "\n",
    "tensor_list = []\n",
    "\n",
    "for csv_file in tqdm(csv_files, desc='Processing CSV files'):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    min_x = df['File X'].min()\n",
    "    min_y = df['File Y'].min()\n",
    "    df['x_norm'] = df['File X'] - min_x\n",
    "    df['y_norm'] = df['File Y'] - min_y\n",
    "    width = int(df['x_norm'].max() + 1)\n",
    "    height = int(df['y_norm'].max() + 1)\n",
    "    num_channels = df.shape[1] - 2\n",
    "    image_array = np.zeros((height, width, num_channels), dtype=np.float32)\n",
    "    for _, row in df.iterrows():\n",
    "        x = int(row['x_norm'])\n",
    "        y = int(row['y_norm'])\n",
    "        channels = row.iloc[2:2+num_channels].values.astype(np.float32)\n",
    "        image_array[y, x, :] = channels\n",
    "    resized_image_array = cv2.resize(image_array, (target_width, target_height))\n",
    "    tensor_image = torch.tensor(resized_image_array).permute(2, 0, 1)\n",
    "    tensor_list.append(tensor_image)\n",
    "    \n",
    "dataset_tensor = torch.stack(tensor_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e337eaa9-1591-4bf5-8473-9dbef9273a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = .\n",
    "tensor_list = []\n",
    "label_list = []\n",
    "\n",
    "for label_str in ['0', '1']:  \n",
    "    label_folder = os.path.join(folder_path, label_str)\n",
    "    csv_files = glob.glob(os.path.join(label_folder, '*.csv'))\n",
    "    label = int(label_str)\n",
    "\n",
    "    for csv_file in tqdm(csv_files, desc=f'Processing label {label}'):\n",
    "        df = pd.read_csv(csv_file)\n",
    "\n",
    "        min_x = df['File X'].min()\n",
    "        min_y = df['File Y'].min()\n",
    "        df['x_norm'] = df['File X'] - min_x\n",
    "        df['y_norm'] = df['File Y'] - min_y\n",
    "\n",
    "        width = int(df['x_norm'].max() + 1)\n",
    "        height = int(df['y_norm'].max() + 1)\n",
    "\n",
    "        num_channels = df.shape[1] - 2\n",
    "        image_array = np.zeros((height, width, num_channels), dtype=np.float32)\n",
    "\n",
    "        for _, row in df.iterrows():\n",
    "            x = int(row['x_norm'])\n",
    "            y = int(row['y_norm'])\n",
    "            channels = row.iloc[2:2+num_channels].values.astype(np.float32)\n",
    "            image_array[y, x, :] = channels\n",
    "\n",
    "        resized = cv2.resize(image_array, (target_width, target_height))\n",
    "        tensor_image = torch.tensor(resized).permute(2, 0, 1)\n",
    "\n",
    "        tensor_list.append(tensor_image)\n",
    "        label_list.append(label)\n",
    "\n",
    "\n",
    "validset_tensor = TensorClassificationDataset(tensor_list, label_list)\n",
    "val_loader = DataLoader(validset_tensor, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88999113-d08f-45ee-8df3-3e073147783c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "train_epochs = 200\n",
    "batch_size = 32\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a4f919-d832-4516-ab7e-62b28c1183c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_test = get_single_channel_transform(channel_index, size=(target_width,target_height), train=False)\n",
    "test_images = []\n",
    "test_labels = []\n",
    "for img, label in tqdm(zip(tensor_list, label_list), total=len(tensor_list)):\n",
    "    treat_img = transform_test(img)  \n",
    "    test_images.append(treat_img)\n",
    "    test_labels.append(label)\n",
    "\n",
    "test_data = torch.stack(test_images) \n",
    "test_targets = torch.tensor(test_labels)  \n",
    "\n",
    "test_dataset = TensorDataset(test_data, test_targets)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, generator=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d8a690-1d24-4236-8f8c-3abf680facda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    learning_rate = trial.suggest_float(\"lr\", 1e-5, 1e-2, log=True)\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-6, 1e-2, log=True)\n",
    "\n",
    "    transform_train = get_single_channel_transform(channel_index, size=(target_width,target_height), train=False)\n",
    "    train_images = []\n",
    "    for img in tqdm(dataset_tensor, total=len(dataset_tensor)):\n",
    "        treat_img = transform_test(img)  \n",
    "        train_images.append(treat_img)\n",
    "    \n",
    "    train_data = torch.stack(train_images) \n",
    "    \n",
    "    val_ratio = 0.2\n",
    "    val_size = int(len(train_data) * val_ratio)\n",
    "    train_size = len(train_data) - val_size\n",
    "    train_dataset, val_dataset = random_split(\n",
    "        TensorDataset(train_data, train_data),\n",
    "        [train_size, val_size],\n",
    "        generator=torch.Generator().manual_seed(42)\n",
    "    )\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, generator=g)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    model = UNetAutoencoder(in_channels=1, out_channels=1, features=[16, 32, 64, 128]).to(device)\n",
    "    optimizer = AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "    best_val_loss = float(\"inf\")\n",
    "    patience_counter = 0\n",
    "    improvement_threshold = 0.00005\n",
    "    early_stopping_patience = 10\n",
    "\n",
    "    for epoch in range(train_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        progress = tqdm(train_loader, desc=f\"[Trial {trial.number}] Epoch {epoch+1}/{train_epochs}\", leave=False)\n",
    "        for inputs, targets in progress:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item() * inputs.size(0)\n",
    "        avg_train_loss = total_loss / len(train_loader.dataset)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for val_inputs, val_targets in val_loader:\n",
    "                val_inputs, val_targets = val_inputs.to(device), val_targets.to(device)\n",
    "                val_outputs = model(val_inputs)\n",
    "                loss = criterion(val_outputs, val_targets)\n",
    "                val_loss += loss.item() * val_inputs.size(0)\n",
    "        avg_val_loss = val_loss / len(val_loader.dataset)\n",
    "\n",
    "        tqdm.write(f\"[Trial {trial.number}] Epoch {epoch+1} Train Loss: {avg_train_loss:.6f} | Val Loss: {avg_val_loss:.6f}\")\n",
    "\n",
    "        if best_val_loss - avg_val_loss > improvement_threshold:\n",
    "            best_val_loss = avg_val_loss\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= early_stopping_patience:\n",
    "                break\n",
    "\n",
    "    model.eval()\n",
    "    all_anomaly_scores = []\n",
    "    all_true_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for test_batch in tqdm(test_loader, desc=f\"[Trial {trial.number}] Evaluating\", leave=False):\n",
    "            test_image_tensor, test_label = test_batch\n",
    "            test_image_tensor = test_image_tensor.to(device)\n",
    "            reconstructed = model(test_image_tensor)\n",
    "            batch_scores = ((reconstructed - test_image_tensor) ** 2).view(test_image_tensor.size(0), -1).mean(dim=1)\n",
    "            all_anomaly_scores.extend(batch_scores.cpu().numpy())\n",
    "            all_true_labels.extend(test_label.cpu().numpy())\n",
    "\n",
    "    # ----- 5. Threshold sweep -----\n",
    "    anomaly_scores = np.array(all_anomaly_scores)\n",
    "    true_labels = np.array(all_true_labels).astype(int)\n",
    "    \n",
    "    best_acc = 0\n",
    "    best_sen = 0\n",
    "    best_spe = 0\n",
    "    best_threshold = None\n",
    "    thresholds = np.linspace(anomaly_scores.min(), anomaly_scores.max(), 1000)\n",
    "    for threshold in thresholds:\n",
    "        pred_labels = (anomaly_scores > threshold).astype(int)\n",
    "    \n",
    "        acc = accuracy_score(true_labels, pred_labels)\n",
    "        sen = recall_score(true_labels, pred_labels, pos_label=1)\n",
    "        pre = precision_score(true_labels, pred_labels, pos_label=1, zero_division=0)\n",
    "    \n",
    "        tn, fp, fn, tp = confusion_matrix(true_labels, pred_labels).ravel()\n",
    "        spe = tn / (tn + fp + 1e-8)\n",
    "    \n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_sen = sen\n",
    "            best_spe = spe\n",
    "            best_threshold = threshold\n",
    "    \n",
    "    tqdm.write(f\"[Trial {trial.number}] Best Accuracy   : {best_acc:.4f}\")\n",
    "    tqdm.write(f\"[Trial {trial.number}] Best Sensitivity: {best_sen:.4f}\")\n",
    "    tqdm.write(f\"[Trial {trial.number}] Best Specificity: {best_spe:.4f}\")\n",
    "    tqdm.write(f\"[Trial {trial.number}] Best Threshold  : {best_threshold:.6f}\")\n",
    "    \n",
    "    return best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0d4614-9180-44dd-97da-67a8d0f34ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=30)\n",
    "\n",
    "print(f\" Best trial: {study.best_trial.number}\")\n",
    "print(f\"  ACC: {study.best_value:.4f}\")\n",
    "print(f\"  lr: {study.best_params['lr']}\")\n",
    "print(f\"  weight_decay: {study.best_params['weight_decay']}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
